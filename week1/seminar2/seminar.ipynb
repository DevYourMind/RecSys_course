{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f03f3-e355-46cf-84c0-13af9796d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Iterable, Iterator, NamedTuple, Optional, Set, Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "\n",
    "from animus import ICallback, IExperiment\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "sns.set(rc={\"figure.figsize\":(15, 5)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94130d65-fcc9-4c89-a152-9af7a140893c",
   "metadata": {},
   "source": [
    "# Что по данным?\n",
    "\n",
    "В этом семинаре мы будем экспериментировать с датасетом MovieLens 10M.\n",
    "Это один из самых известных датасетов для исследования рекомендательных моделей, поэтому вы его ещё не раз встретите в статья.\n",
    "\n",
    "Датасет на самом деле очень простой. У нас есть user, item и рейтинг user для item. Рейтинг - explicit величина, которая принимает значения от 0 до 5. Кроме того, есть ещё метадата для фильмов, если мы захотим обучить что-то на основе контента. Однако последнее нам не понадобится))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a14e7-4c22-4073-84cb-06607e73e413",
   "metadata": {},
   "source": [
    "## Step 0: Получим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee473ef-a62f-41a9-9b5d-fcb38de953f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://files.grouplens.org/datasets/movielens/ml-10m.zip\n",
    "!unzip -uo ml-10m.zip -d data\n",
    "# Приведем к формату csv ratings\n",
    "!awk 'BEGIN { print \"user,item,values,timestamp\" } { gsub(/::/, \",\", $0); print $0 }' data/ml-10M100K/ratings.dat > data/ml-10M100K/ratings.csv\n",
    "# Приведем к формату csv movies\n",
    "!awk 'BEGIN { print \"item,title,genres\" } { gsub(/::/, \",\", $0); print $0 }' data/ml-10M100K/movies.dat > data/ml-10M100K/movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6679bb9-3bf8-4457-a8e3-979a1b1cdbbe",
   "metadata": {},
   "source": [
    "Eeeeeeee\n",
    "\n",
    "Looks good!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560d3d2-9a24-4670-82b0-04da25ca59c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/ml-10M100K/ratings.csv data/ml-10M100K/movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8155de5c-b223-426b-9c45-23559363a949",
   "metadata": {},
   "source": [
    "## Step 1: Посмотрим на данные... КОРОЧЕ EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564a48d-8ca3-4f48-aedf-675069ce24eb",
   "metadata": {},
   "source": [
    "### 1: Распарсим данные из csv в pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740b68db-9281-4aca-be02-4cd2c107f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"data/ml-10M100K/ratings.csv\")\n",
    "ratings[\"timestamp\"] = pd.to_datetime(ratings[\"timestamp\"], unit=\"s\")\n",
    "ratings.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54139d-e01f-431d-aba1-cff584d6eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape, ratings.user.unique().shape, ratings.item.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd865448-14a1-4329-a363-3c26b64ba23e",
   "metadata": {},
   "source": [
    "### 2: Посмотрим на распределение рейтингов в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3402c-30f4-41a1-a9c7-7dbd21372a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=ratings[\"values\"], binwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36ee08-7fe8-409c-a7ca-942b27da24ae",
   "metadata": {},
   "source": [
    "### 3: Построим Rating Distribution\n",
    "\n",
    "Вы спросите, а что такое Rating Distribution?\n",
    "\n",
    "Это просто fancy название графика, который, грубо говоря, показывает отношение количества рейтингов к количеству юзеров. Он отлично подходит, чтобы popularity-skew в данных.\n",
    "\n",
    "По оси y располагаем количество рейтингов, выраженное в процентах от общего количества.\n",
    "По оси x - айтемы сортированные в порядке убывания по количество рейтингов на них. Ну и также ставим для них в качестве id - процент."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cf3a2-01ab-47e3-9751-042289a1bf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rating_distribution(column: str) -> None:\n",
    "    # Compute\n",
    "    ratings_dist = ratings[column].value_counts(normalize=True).reset_index()\n",
    "    ratings_dist.columns = [column, \"num_ratings_percent\"]\n",
    "    step = 1 / (ratings_dist.shape[0] - 1)\n",
    "    ratings_dist[f\"{column}_percent\"] = np.arange(0, 1 + step, step) * 100\n",
    "    ratings_dist[\"num_ratings_percent\"] = np.cumsum(ratings_dist[\"num_ratings_percent\"]) * 100\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.lineplot(data=ratings_dist, x=f\"{column}_percent\", y=\"num_ratings_percent\", ax=ax)\n",
    "    ax.set_xlim(0, 100)\n",
    "    ax.set_xticks(range(0, 101, 2))\n",
    "    ax.set_title(\"Rating Distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104808b-8e24-4911-9ce0-2be5db53133e",
   "metadata": {},
   "source": [
    "Для item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed144cb-9750-467d-bdda-5f1570671737",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_distribution(column=\"item\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931dd198-7134-4921-ae8b-91f924cc250c",
   "metadata": {},
   "source": [
    "Для user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38695887-6fc6-446f-a462-4dda862192f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_distribution(column=\"user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74c09d-09aa-47d0-9e1c-e3cbe0d8a7cf",
   "metadata": {},
   "source": [
    "## Step 2: Мы почистим, мы помоем\n",
    "\n",
    "### 1: Сделаем простенькую фильтрацию\n",
    "\n",
    "Ниже есть несколько удобных функций, с которыми можно поиграться:\n",
    "- **valid_items**\n",
    "    - получим элементы, которые встречаются реже чем threshold. Полезно, чтобы исключить супер популярные айтемы и активных юзеров.\n",
    "- **filter_ratings**\n",
    "    - оставим только рейтинги выше `min_rating` (полезно если хотим сделать implicit датасте)\n",
    "    - оставим users и items, которые встречаются не реже `min_user_count`, `min_item_count` соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8aaa41-d1e3-4e63-b556-fef272af0bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_elements(data: pd.DataFrame, column: str, threshold: float = 0.2) -> Set[int]:\n",
    "    rating_dist = data[column].value_counts().reset_index()\n",
    "    cut_off = round(threshold * rating_dist.shape[0]) + 1\n",
    "    return set(rating_dist.index[cut_off:])\n",
    "\n",
    "\n",
    "def get_count(data: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    grouped_by_column = data.groupby(column, as_index=False)\n",
    "    return grouped_by_column.size()\n",
    "\n",
    "\n",
    "def _filter_ratings(\n",
    "    data: pd.DataFrame,\n",
    "    min_rating: float = 3.0,\n",
    "    min_user_count: int = 3,\n",
    "    min_item_count: int = 3,\n",
    ") -> pd.DataFrame:\n",
    "    if min_rating is not None:\n",
    "        data = data.loc[data[\"values\"] > min_rating]\n",
    "    if min_item_count > 0:\n",
    "        itemcount = get_count(data, column=\"item\")\n",
    "        data = data.loc[data[\"item\"].isin(itemcount.item[itemcount[\"size\"] >= min_item_count])]\n",
    "    if min_user_count > 0:\n",
    "        usercount = get_count(data, column=\"user\")\n",
    "        data = data.loc[data[\"user\"].isin(usercount.user[usercount[\"size\"] >= min_user_count])]\n",
    "    return data\n",
    "\n",
    "\n",
    "def filter_ratings(\n",
    "    data: pd.DataFrame,\n",
    "    min_rating: float = 3.0,\n",
    "    min_user_count: int = 3,\n",
    "    min_item_count: int = 3,\n",
    "    remove_top_items: float = 0.02,\n",
    ") -> pd.DataFrame:\n",
    "    if remove_top_items > 0:\n",
    "        valid_items = valid_elements(data, column=\"item\")\n",
    "        data = data.loc[data[\"item\"].isin(valid_items)]\n",
    "    while True:\n",
    "        cur_num_rows = data.shape[0]\n",
    "        data = _filter_ratings(data, min_rating, min_user_count, min_item_count)\n",
    "        new_num_rows = data.shape[0]\n",
    "        if cur_num_rows == new_num_rows:\n",
    "            break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c931d330-c3f4-4814-8989-6559122eaa2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "implicit_filtered_ratings = filter_ratings(ratings)\n",
    "print(f\"Before: {ratings.shape}; After: {implicit_filtered_ratings.shape}\")\n",
    "explicit_filtered_ratings = filter_ratings(ratings, min_rating=None)\n",
    "print(f\"Before: {ratings.shape}; After: {explicit_filtered_ratings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0119c0-d35e-46ac-a5e4-0b202a317e45",
   "metadata": {},
   "source": [
    "### 2: Построим encoder для user и item\n",
    "\n",
    "Вместо кастомного encoder можно использовать [sklearn.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html), однако `pickle зло` поэтому напишем свой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f4a68-5ff6-4dd0-99d7-5ad288d002c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NamespaceEncoder:\n",
    "    item_to_idx: dict[str, int] = field(default_factory=dict)\n",
    "    idx_to_item: dict[str, str] = field(default_factory=dict)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self.add(\"@@OOV@@\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.item_to_idx)\n",
    "\n",
    "    def add(self, item: str) -> None:\n",
    "        idx = len(self.item_to_idx)\n",
    "        self.item_to_idx[item] = idx\n",
    "        self.idx_to_item[str(idx)] = item\n",
    "\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self) -> None:\n",
    "        self.namespaces = {\"user\": NamespaceEncoder(), \"item\": NamespaceEncoder()}\n",
    "\n",
    "    def encode(self, data: Iterable[str], namespace: str = \"user\") -> list[str]:\n",
    "        encoder = self.namespaces[namespace].item_to_idx\n",
    "        return [encoder.get(x, 0) for x in data if x in encoder]\n",
    "\n",
    "    def decode(self, data: Iterable[Union[str, int]], namespace: str = \"user\") -> list[str]:\n",
    "        decoder = self.namespaces[namespace].idx_to_item\n",
    "        return [decoder.get(x, \"@@OOV@@\") for x in map(str, data) if x in decoder]\n",
    "\n",
    "    def fit(self, data: pd.DataFrame) -> \"Encoder\":\n",
    "        for attr, encoder in self.namespaces.items():\n",
    "            for item in data[attr].unique():\n",
    "                encoder.add(item)\n",
    "        return self\n",
    "\n",
    "    def transform(self, data: pd.DataFrame, decode: bool = False) -> pd.DataFrame:\n",
    "        data_copy = data.copy()\n",
    "        data_copy = data_copy[\n",
    "            data_copy.user.isin(set(self.namespaces[\"user\"].item_to_idx))\n",
    "            & data_copy.item.isin(set(self.namespaces[\"item\"].item_to_idx))\n",
    "        ]\n",
    "        for attr in self.namespaces:\n",
    "            func = self.encode if not decode else self.decode\n",
    "            data_copy[attr] = func(data_copy[attr].values, namespace=attr)\n",
    "        return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b368a-7630-4c71-9dea-627aedb08109",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder().fit(explicit_filtered_ratings)\n",
    "implicit_filtered_ratings = encoder.transform(implicit_filtered_ratings)\n",
    "explicit_filtered_ratings = encoder.transform(explicit_filtered_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844841f-52a8-4064-a452-4f1f21a3f0ac",
   "metadata": {},
   "source": [
    "### 3: Выберем себе тестовые данные\n",
    "\n",
    "Вот просто так, решили, что для тестирования наших рекомендов возьмём последний **год** из базы. На остальном будем обучаться.\n",
    "\n",
    "Необязательно подходить именно таким образом для создания тестового и валидационного датасетов.\n",
    "Далее в курсе мы подробно обсудим различные подходы для разделения данных в RecSys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbcc599-a063-425f-9070-017e3bb298b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts_split = {\n",
    "    \"implicit\": implicit_filtered_ratings[\"timestamp\"].max() - pd.Timedelta(365, \"days\"),\n",
    "    \"explicit\": explicit_filtered_ratings[\"timestamp\"].max() - pd.Timedelta(365, \"days\"),\n",
    "}\n",
    "datasets = {}\n",
    "for key, dataset in ((\"implicit\", implicit_filtered_ratings), (\"explicit\", explicit_filtered_ratings)):\n",
    "    datasets[key] = {\n",
    "        \"train\": dataset.loc[dataset[\"timestamp\"] <= ts_split[key]],\n",
    "        \"valid\": dataset.loc[dataset[\"timestamp\"] > ts_split[key]],\n",
    "    }\n",
    "    datasets[key][\"valid\"] = datasets[key][\"valid\"].loc[datasets[key][\"valid\"].user.isin(datasets[key][\"train\"].user.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacef218-c4b3-43cc-9963-39f0190da68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sparse(dataset: pd.DataFrame, encoder: Encoder, binary: bool = False) -> sps.csr_matrix:\n",
    "    shape = len(encoder.namespaces[\"user\"]), len(encoder.namespaces[\"item\"])\n",
    "    values = dataset[\"values\"].to_numpy()\n",
    "    values = np.ones_like(values) if binary else values\n",
    "    return sps.csr_matrix((values, (dataset[\"user\"].to_numpy(), dataset[\"item\"].to_numpy())), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a84c60-1ab8-4ee0-b350-5d8bcfb6728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sparse_datasets(\n",
    "    train: pd.DataFrame, valid: pd.DataFrame, encoder: Encoder, binary: bool = True\n",
    ") -> dict[str, sps.csr_matrix]:\n",
    "    train_sparse = make_sparse(train, encoder, binary=binary)\n",
    "    valid_sparse = make_sparse(valid, encoder, binary=binary)\n",
    "    train_mask, valid_mask = train_sparse.getnnz(axis=-1) > 0, valid_sparse.getnnz(axis=-1) > 0\n",
    "    return {\n",
    "        \"train\": {\"source\": train_sparse[train_mask], \"target\": train_sparse[train_mask]},\n",
    "        \"valid\": {\"source\": train_sparse[valid_mask], \"target\": valid_sparse[valid_mask]},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7fafd3-485a-4c21-9c49-6b9c3694c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "\n",
    "explicit_datasets = build_sparse_datasets(**datasets[\"explicit\"], encoder=encoder, binary=False)\n",
    "implicit_datasets = build_sparse_datasets(**datasets[\"implicit\"], encoder=encoder, binary=True)\n",
    "print(\"Explicit\")\n",
    "pprint.pprint(explicit_datasets)\n",
    "print(\"Implicit\")\n",
    "pprint.pprint(implicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ec922-f440-4c87-95de-414ac9d7b205",
   "metadata": {},
   "source": [
    "## 4: Обучим модельки\n",
    "\n",
    "Сразу будем писать всё на torch, because we can!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f349885-bd34-46f8-b0d9-3d628b20f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, source: sps.csc_matrix, target: sps.csr_matrix = None) -> None:\n",
    "        self._source = source\n",
    "        self._target = target\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._source.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict[str, np.ndarray]:\n",
    "        item = {\"source\": self._source[idx], \"idx\": idx}\n",
    "        if self._target is not None:\n",
    "            item[\"target\"] = self._target[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc506a39-3880-4080-b2b8-3fdfb47d6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensCollator:\n",
    "    def __call__(self, instances: Iterable[dict[str, sps.csr_matrix]]) -> dict[str, torch.Tensor]:\n",
    "        batch = self._make_batch(instances)\n",
    "        for key, tensor in batch.items():\n",
    "            batch[key] = (\n",
    "                self._to_sparse(tensor).to_dense().float()\n",
    "                if isinstance(tensor[0], sps.csr_matrix)\n",
    "                else torch.Tensor(tensor)\n",
    "            )\n",
    "        return dict(batch)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_batch(instances: Iterable[dict[str, sps.csr_matrix]]) -> dict[str, list[sps.csr_matrix]]:\n",
    "        tensor_dict = defaultdict(list)\n",
    "        for instance in instances:\n",
    "            for field, tensor in instance.items():\n",
    "                tensor_dict[field].append(tensor)\n",
    "        return tensor_dict\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_sparse(tensor: list[sps.csr_matrix]) -> torch.sparse.Tensor:\n",
    "        tensor = sps.vstack(tensor)\n",
    "        values = torch.from_numpy(tensor.data)\n",
    "        indices = torch.from_numpy(np.vstack(tensor.nonzero())).long()\n",
    "        sparse_tensor = torch.sparse.FloatTensor(indices, values, tensor.shape)\n",
    "        return sparse_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5bcc0-56b1-4f30-b949-5c63e14928f4",
   "metadata": {},
   "source": [
    "### Sparse Model и Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7a0d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7070c-b9ac-40e9-830a-0b5b1864d39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseModel(ABC):\n",
    "    def __init__(self, remove_seen: bool = True) -> None:\n",
    "        self.remove_seen = remove_seen\n",
    "        self.device = torch.device(\"cpu\")\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, data: sps.csr_matrix) -> None:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict_proba(self, batch: dict[str, Any]) -> dict[str, torch.Tensor]:\n",
    "        pass\n",
    "\n",
    "    def to(self, device: torch.device) -> \"SparseModel\":\n",
    "        self.device = device\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de63b45-44cf-4e9c-920d-7dadf4429e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseRunner(IExperiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SparseModel,\n",
    "        seed: int = 13,\n",
    "        batch_size: int = 32,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        callbacks: dict[str, ICallback] = None,\n",
    "        target_threshold: float = 0.0,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.seed = seed\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.callbacks = callbacks or defaultdict(None)\n",
    "        self._batch_size = batch_size\n",
    "        self._target_threshold = target_threshold\n",
    "        # Extra variables\n",
    "        self.batch_output: dict[str, np.ndarray] = None\n",
    "        self.batch_target: np.ndarray = None\n",
    "\n",
    "    def run_dataset(self) -> None:\n",
    "        if self.is_train_dataset:\n",
    "            self.model.fit(self.dataset[\"source\"])\n",
    "        self.dataset = tqdm(\n",
    "            DataLoader(\n",
    "                MovieLensDataset(**self.dataset),\n",
    "                collate_fn=MovieLensCollator(),\n",
    "                batch_size=self._batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=1,\n",
    "                pin_memory=True,\n",
    "            ),\n",
    "            desc=f\"Iterating {self.dataset_key}\",\n",
    "        )\n",
    "        # Remove seen items only for validation\n",
    "        self.model.remove_seen = not self.is_train_dataset\n",
    "        super().run_dataset()\n",
    "\n",
    "    def run_batch(self) -> None:\n",
    "        self.batch = {k: v.to(self.device) for k, v in self.batch.items()}\n",
    "        self.batch_target = self.batch[\"target\"].gt(self._target_threshold).float()\n",
    "        self.batch_output = self.model.predict_proba(self.batch)\n",
    "\n",
    "    def run(self, datasets: dict[str, dict[str, sps.csr_matrix]]) -> None:\n",
    "        self.datasets = datasets\n",
    "        super().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83ee00-4865-439e-8ed6-be358e82f1d1",
   "metadata": {},
   "source": [
    "### Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02456c9-1e80-469f-8d8c-4825395497b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopPopularModel(SparseModel):\n",
    "    def __init__(self, remove_seen: bool = True) -> None:\n",
    "        super().__init__(remove_seen=remove_seen)\n",
    "        self._stats = {}\n",
    "\n",
    "    def fit(self, data: sps.csr_matrix) -> None:\n",
    "        self._stats[\"item_freq\"] = item_freq = torch.from_numpy(\n",
    "            np.array(data.sum(axis=0), dtype=np.float32)\n",
    "        ).view(-1).to(self.device)\n",
    "        self._logits = torch.zeros_like(item_freq).scatter_(\n",
    "            dim=-1,\n",
    "            index=torch.argsort(-item_freq),\n",
    "            src=torch.arange(item_freq.size(-1), 0, -1, dtype=torch.float, device=self.device)\n",
    "        )\n",
    "\n",
    "    def predict_proba(self, batch: dict[str, Any]) -> dict[str, torch.Tensor]:\n",
    "        scores = self._logits.repeat(batch[\"source\"].size(0), 1)\n",
    "        if self.remove_seen:\n",
    "            scores[batch[\"source\"].gt(0)] = -1e13\n",
    "        return {\"logits\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260ab5d-1b24-4ce1-a136-6b2b2b7e328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_popular = SparseRunner(model=TopPopularModel(), device=device)\n",
    "print(\"Implicit\")\n",
    "top_popular.run(implicit_datasets)\n",
    "print(\"Explicit\")\n",
    "top_popular.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a103af1-2f93-48bc-ae16-2f1e4d290e2d",
   "metadata": {},
   "source": [
    "### ItemKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1eb441-6455-47f8-b9c0-fda577323975",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNNModel(SparseModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        similarity: str,\n",
    "        topk: int,\n",
    "        count_threshold: int = None,\n",
    "        method: str = \"item\",\n",
    "        remove_seen: bool = True,\n",
    "    ) -> None:\n",
    "        super().__init__(remove_seen=remove_seen)\n",
    "        assert similarity in (\"cooccurrence\", \"cosine\", \"jaccard\")\n",
    "        self._similarity = getattr(self, similarity)\n",
    "        self._topk = topk\n",
    "        self._count_threshold = count_threshold\n",
    "        self._method = method\n",
    "\n",
    "    def cooccurrence(self, data: sps.csr_matrix) -> torch.Tensor:\n",
    "        if self._method == \"user\":\n",
    "            # sim_matrix ~ (num users, num users)\n",
    "            sim_matrix = torch.from_numpy(data.dot(data.T).toarray()).to(self.device)\n",
    "        else:\n",
    "            # sim_matrix ~ (num items, num items)\n",
    "            sim_matrix = torch.from_numpy(data.T.dot(data).toarray()).to(self.device)\n",
    "        if self._count_threshold is not None:\n",
    "            sim_matrix *= sim_matrix > self._count_threshold\n",
    "        return sim_matrix\n",
    "\n",
    "    def cosine(self, data: sps.csr_matrix) -> torch.Tensor:\n",
    "        if self._method == \"user\":\n",
    "            # sim_matrix ~ (num users, num users)\n",
    "            sim_matrix = torch.from_numpy(data.dot(data.T).toarray()).to(self.device)\n",
    "            # sum_of_squares ~ (num users)\n",
    "            sum_of_squares = torch.from_numpy(\n",
    "                data.power(2).sum(axis=1)\n",
    "            ).to(self._device).view(-1).sqrt()\n",
    "        else:\n",
    "            # sim_matrix ~ (num items, num items)\n",
    "            sim_matrix = torch.from_numpy(data.T.dot(data).toarray()).to(self.device)\n",
    "            # sum_of_squares ~ (num items)\n",
    "            sum_of_squares = torch.from_numpy(\n",
    "                data.power(2).sum(axis=0)\n",
    "            ).to(self.device).view(-1).sqrt()\n",
    "        if self._count_threshold is not None:\n",
    "            sim_matrix *= sim_matrix > self._count_threshold\n",
    "        denominator = torch.einsum(\"i,j->ij\", sum_of_squares, sum_of_squares) + 1e-13\n",
    "        sim_matrix = sim_matrix / denominator\n",
    "        sim_matrix.fill_diagonal_(0.0)\n",
    "        return sim_matrix\n",
    "\n",
    "    def jaccard(self, data: sps.csr_matrix) -> torch.Tensor:\n",
    "        if self._method == \"user\":\n",
    "            # intersaction ~ (num users, num users)\n",
    "            intersaction = torch.from_numpy(data.dot(data.T).toarray()).to(self.device)\n",
    "        else:\n",
    "            # intersaction ~ (num items, num items)\n",
    "            intersaction = torch.from_numpy(data.T.dot(data).toarray()).to(self.device)\n",
    "        if self._count_threshold is not None:\n",
    "            intersaction *= intersaction > self._count_threshold\n",
    "        diagonal = intersaction.diagonal()\n",
    "        return intersaction / (diagonal.unsqueeze(0) + diagonal.unsqueeze(-1) - intersaction)\n",
    "\n",
    "    def fit(self, data: sps.csr_matrix) -> None:\n",
    "        topk = min(self._topk or data.shape[-1] - 1, data.shape[-1] - 1)\n",
    "        similarity_matrix = self._similarity(data).float()\n",
    "        relevant = torch.topk(similarity_matrix, k=topk, dim=-1)\n",
    "        self._similarity_matrix = torch.zeros_like(similarity_matrix).scatter_(\n",
    "            dim=-1, index=relevant.indices, src=relevant.values\n",
    "        )\n",
    "\n",
    "    def predict_proba(self, batch: dict[str, Any]) -> dict[str, torch.Tensor]:\n",
    "        scores = torch.einsum(\"bi,ij->bj\", batch[\"source\"], self._similarity_matrix)\n",
    "        if self.remove_seen:\n",
    "            scores[batch[\"source\"].gt(0)] = -1e13\n",
    "        return {\"logits\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef9422c-ca6c-4b72-b6c2-52bd0e2dd930",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = SparseRunner(model=KNNModel(\"cosine\", topk=100), device=device)\n",
    "print(\"Implicit\")\n",
    "knn_model.run(implicit_datasets)\n",
    "print(\"Explicit\")\n",
    "knn_model.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7a810f-cd0b-4060-8288-0782eb580544",
   "metadata": {},
   "source": [
    "### EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a562b001-6285-4208-bc2d-4e4d4c8c781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EASE(SparseModel):\n",
    "    def __init__(self, remove_seen: bool = True, lambda_weight: float = 100.0) -> None:\n",
    "        super().__init__(remove_seen=remove_seen)\n",
    "        self._lambda_weight = lambda_weight\n",
    "        self._item_matrix = None\n",
    "\n",
    "    def fit(self, data: sps.csr_matrix) -> None:\n",
    "        X = torch.sparse.FloatTensor(\n",
    "            torch.from_numpy(np.vstack(data.nonzero())).long(),\n",
    "            torch.from_numpy(data.data),\n",
    "            data.shape,\n",
    "        )\n",
    "        gram_matrix = torch.sparse.mm(X.transpose(0, 1), X)\n",
    "        gram_matrix += self._lambda_weight * torch.eye(gram_matrix.shape[0]).to_sparse()\n",
    "        gram_matrix = gram_matrix.to_dense().to(self.device)\n",
    "        precision_matrix = torch.linalg.inv(gram_matrix)\n",
    "        item_matrix = precision_matrix / (-torch.diag(precision_matrix))\n",
    "        item_matrix.fill_diagonal_(0.0)\n",
    "        self._item_matrix = item_matrix.float()\n",
    "\n",
    "    def predict_proba(self, batch: dict[str, Any]) -> dict[str, torch.Tensor]:\n",
    "        scores = torch.einsum(\"bi,ij->bj\", batch[\"source\"], self._item_matrix)\n",
    "        if self.remove_seen:\n",
    "            scores[batch[\"source\"].gt(0)] = -1e13\n",
    "        return {\"logits\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d693eb8-ff5f-4b60-bd3b-738422e889df",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(model=EASE(), batch_size=512, device=device)\n",
    "runner.run(implicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0713e69-8a9a-4ab8-9952-82db6a96db60",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5e411a-5fd3-466f-b4c9-b13ca992bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SvdModel(SparseModel):\n",
    "    def __init__(self, factors: int, remove_seen: bool = True) -> None:\n",
    "        super().__init__(remove_seen=remove_seen)\n",
    "        self._factors = factors\n",
    "        self.factors = {}\n",
    "        self.sigma = None\n",
    "\n",
    "    def fit(self, data: sps.csr_matrix) -> None:\n",
    "        # Torch argues on negative stride with u and sigma\n",
    "        u, sigma, vt = sps.linalg.svds(data, k=self._factors)\n",
    "        self.factors = {\n",
    "            \"user\": torch.from_numpy(u.copy()).float().to(self.device),\n",
    "            \"item\": torch.einsum(\"fi->if\", torch.from_numpy(vt).float().to(self.device)),\n",
    "        }\n",
    "        self.sigma = torch.from_numpy(sigma.copy()).diag().float().to(self.device)\n",
    "\n",
    "    def predict_proba(self, batch: dict[str, Any]) -> dict[str, torch.Tensor]:\n",
    "        scores = torch.einsum(\n",
    "            \"ui,if,jf->uj\", batch[\"source\"], self.factors[\"item\"], self.factors[\"item\"]\n",
    "        )\n",
    "        if self.remove_seen:\n",
    "            scores[batch[\"source\"].gt(0)] = -1e13\n",
    "        return {\"logits\": scores}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283f8b5-9a47-4c77-8f58-a03d545fc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(model=SvdModel(factors=128), batch_size=512, device=device)\n",
    "print(\"Implicit\")\n",
    "runner.run(implicit_datasets)\n",
    "print(\"Explicit\")\n",
    "runner.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bb7af-a0d7-4320-bb5b-2784f8c89aa0",
   "metadata": {},
   "source": [
    "## 5: Считаем метрички\n",
    "\n",
    "Так как, мы всё делаем поверху animus, сдеалем 2 callback, чтобы красиво визуализировать метрики моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c053209-51c0-4caf-b4dd-dcc8d57cca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricCallback(ICallback):\n",
    "    def __init__(self, func: Callable, topk: list[int], input_key: str) -> None:\n",
    "        self._name = func.__name__\n",
    "        self._func = func\n",
    "        self._topk = topk\n",
    "        self._input_key = input_key\n",
    "        self._total_sum = {k: 0 for k in self._topk}\n",
    "        self._num_batches = 0\n",
    "\n",
    "    def _get_metric(self) -> dict[str, float]:\n",
    "        return {\n",
    "            f\"{self._name}@{k}\": metric_sum / self._num_batches\n",
    "            for k, metric_sum in self._total_sum.items()\n",
    "        }\n",
    "\n",
    "    def on_dataset_start(self, exp: IExperiment) -> None:\n",
    "        self._total_sum = {k: 0 for k in self._topk}\n",
    "        self._num_batches = 0\n",
    "\n",
    "    def on_batch_end(self, exp: IExperiment) -> None:\n",
    "        for k in self._topk:\n",
    "            self._total_sum[k] += self._func(\n",
    "                exp.batch_output[self._input_key], exp.batch_target, topk=k\n",
    "            ).item()\n",
    "        self._num_batches += 1\n",
    "        exp.batch_metrics.update(self._get_metric())\n",
    "\n",
    "    def on_dataset_end(self, exp: IExperiment) -> None:\n",
    "        exp.dataset_metrics.update(self._get_metric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c5594-20ec-450c-9fa1-e674d8fa8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggerCallback(ICallback):\n",
    "    def on_dataset_end(self, exp: IExperiment) -> None:\n",
    "        \"\"\"Run callbacks on dataset end.\"\"\"\n",
    "        print(f\"{exp.dataset_key.capitalize()} metrics:\")\n",
    "        max_length = max(len(x) for x in exp.dataset_metrics)\n",
    "        # Sort by length to make it prettier\n",
    "        for metric in sorted(exp.dataset_metrics, key=self._sort_func):\n",
    "            metric_value = exp.dataset_metrics.get(metric)\n",
    "            if isinstance(metric_value, (float, int)):\n",
    "                print(f\"{metric.ljust(max_length)} | {metric_value:.4f}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _sort_func(x: str) -> Tuple[int, str, int]:\n",
    "        if \"@\" in x:\n",
    "            metric_key, topk = x.split(\"@\")\n",
    "            return (len(metric_key), metric_key, int(topk))\n",
    "        return (len(x), x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac654b68-ae10-4d97-9b1e-4b6f41d865c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareTargetResult(NamedTuple):\n",
    "    values: torch.Tensor\n",
    "    indices: torch.Tensor\n",
    "\n",
    "\n",
    "def validate_metric_inputs(output: torch.Tensor, target: torch.Tensor) -> None:\n",
    "    if output.size() != target.size():\n",
    "        raise IndexError(\n",
    "            \"Unequal sizes for output and target: \"\n",
    "            f\"output - {output.size()}, target - {target.size()}.\"\n",
    "        )\n",
    "    if not (target.eq(0) | target.eq(1)).all():\n",
    "        raise ValueError(\n",
    "            \"Target contains values outside of 0 and 1.\" f\"\\nTarget:\\n{target}\"\n",
    "        )\n",
    "\n",
    "\n",
    "def prepare_target(\n",
    "    output: torch.Tensor, target: torch.Tensor, return_indices: bool = False\n",
    ") -> Union[torch.Tensor, PrepareTargetResult]:\n",
    "    validate_metric_inputs(output, target)\n",
    "    # Define order by sorted output scores.\n",
    "    indices = output.argsort(dim=-1, descending=True)\n",
    "    sorted_target = torch.gather(target, index=indices, dim=-1)\n",
    "    return (\n",
    "        PrepareTargetResult(sorted_target, indices) if return_indices else sorted_target\n",
    "    )\n",
    "\n",
    "\n",
    "def nan_to_num(tensor: torch.Tensor, nan: float = 0.0) -> torch.Tensor:\n",
    "    return torch.where(\n",
    "        torch.isnan(tensor) | torch.isinf(tensor),\n",
    "        torch.full_like(tensor, fill_value=nan),\n",
    "        tensor,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c369037-0686-4e4f-96f7-324c16133d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, target = torch.randn(size=(10, 13)), torch.randint(low=0, high=2, size=(10, 13)).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dcf517-e8df-4957-92d2-c29e948116cd",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a35ba-cabc-4071-9b84-93e21903d0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    topk = min(output.size(-1), topk)\n",
    "    # target_sorted_by_output ~ (users, topk)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    # YOUR CODE HERE\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebfb1f-9b44-4161-b38f-f70343a018e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision(output, target, topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78531082-a94d-4347-a6ac-4b21f1effaf3",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1d6167-344f-4041-9c97-d29eeb232f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    topk = min(output.shape[-1], topk)\n",
    "    # target_sorted_by_output ~ (users, topk)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    # YOUR CODE HERE\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4804ee24-b4c5-46e2-8c1e-a08a48cba535",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall(output, target, topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cffedd-d538-4876-a7af-d569de374a76",
   "metadata": {},
   "source": [
    "### Mean (Normalized) Average Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4327a51-0231-4780-9292-a6001b941765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnap(output: torch.Tensor, target: torch.Tensor, topk: int, normalized: bool = True) -> torch.Tensor:\n",
    "    topk = min(output.size(-1), topk)\n",
    "    # target_sorted_by_output ~ (users, topk)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    # YOUR CODE HERE\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46f2fd9-7d29-465c-904d-1789e9a9855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnap(output, target, topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3d382e",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cumulative Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e513c99-38c5-45c5-8c71-cc8ce7fe0f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(tensor: torch.Tensor) -> torch.Tensor:\n",
    "    gains = (2**tensor) - 1\n",
    "    discounts = 1 / torch.log2(torch.arange(0, tensor.size(-1), dtype=torch.float, device=tensor.device) + 2.0)\n",
    "    return gains * discounts\n",
    "\n",
    "\n",
    "def ndcg(output: torch.Tensor, target: torch.Tensor, topk: int) -> torch.Tensor:\n",
    "    topk = min(output.size(-1), topk)\n",
    "    # target_sorted_by_output ~ (users, items)\n",
    "    target_sorted_by_output = prepare_target(output, target)\n",
    "    ideal_target = prepare_target(target, target)\n",
    "    # YOUR CODE HERE\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95e737-7853-4c7d-bcb4-1e2999ed3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg(output, target, topk=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904b6b0-b7cf-4191-9522-42d6a03795a2",
   "metadata": {},
   "source": [
    "## LESSS GOOOOOO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b5c7d2-9d3f-49e2-91da-8a7c7879adde",
   "metadata": {},
   "source": [
    "### Top Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea63804-2499-4212-b5c7-2c87466ae9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=TopPopularModel(),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    target_threshold=3.0,\n",
    "    device=device,\n",
    ")\n",
    "runner.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586f03f3-d77b-46af-abea-14fe62425708",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=TopPopularModel(),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(implicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ab55e1-2edb-478e-b30f-3604e743d68f",
   "metadata": {},
   "source": [
    "### Item KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f197d6-0194-4df3-9023-7060f2fc6e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=KNNModel(\"cosine\", topk=100),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(implicit_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecabf8-cd92-4c0e-bcea-9fc575c33f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=KNNModel(\"cosine\", topk=100),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf40a73-c102-4643-9018-2c5f8d09e5eb",
   "metadata": {},
   "source": [
    "### EASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8cce94-5d65-4fd2-921d-42c7ad762c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=EASE(),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(implicit_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6c1c2-ea4b-4f75-8ddb-7089fa9a9d11",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f39327-9274-4ff1-a177-8f0fa4507088",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=SvdModel(factors=32),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(explicit_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d7596-6e6c-45ef-b995-ee3c5a5196ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = SparseRunner(\n",
    "    model=SvdModel(factors=32),\n",
    "    batch_size=512,\n",
    "    callbacks={\n",
    "        \"precision\": MetricCallback(precision, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"recall\": MetricCallback(recall, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"ndcg\": MetricCallback(ndcg, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"map\": MetricCallback(mnap, input_key=\"logits\", topk=(1, 3, 10)),\n",
    "        \"logger\": LoggerCallback(),\n",
    "    },\n",
    "    device=device,\n",
    ")\n",
    "runner.run(implicit_datasets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar-venv",
   "language": "python",
   "name": "seminar-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
