{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Recommender Systems </center>\n",
    "## <center> Content-based & Hybrid approaches. Week 3</center>\n",
    "\n",
    "\n",
    "* Hybrid approaches classification\n",
    "* Lightfm paper & library\n",
    "* Case study: next basket recommendations (X5 retail hero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative filtering vs. Content models\n",
    "\n",
    "В контентных моделях есть недостаток, что нет так называемого трансфер лернинга. То есть, предсказание по пользователя делается отдельно по его фичам (изолированно от других пользователей). Поэтому нужно довольно много хороших признаков по клиентам, что тоже не дает в полной мере решить проблему холодного старта. \n",
    "\n",
    "\n",
    "\n",
    "### LightFM. \n",
    "#### Original paper: Metadata Embeddings for User and Item Cold-start Recommendations (2015). \n",
    "\n",
    "* Это гибридный подход коллаборативной фильтрации и контентной модели, которая предсталвяет эмбеддинги пользователей и эмбеддинги объектов как линейные комбинации из обученных векторов известных признаков - т.е. суммы новых латентных признаков. При этом, это позволяет обучать модель как в режиме без признаков, так и с ними, решая проблему холодного старта (т.к. по новым пользователям и объектам можно использовать их признаки) и проблему слишком разреженных данных (high sparsity problem). LightFM умеет хорошо работает как с плотными, так и с разреженными данными. Как бонус, эмбеддинги признаков кодируют в себе семантическую информацию по аналогии с подходами для получения эмбеддингов слов (например, w2v).\n",
    "\n",
    "*  Формализация. Пусть: <br> $U$ - множество пользователей, <br> $I$ - множество объектов, <br> $F^{U}$ - множество признаков пользователей, <br> $F^{I}$- множество признаков объектов. <br>\n",
    "Все пары $(u, i) \\in U × I$ - это объединение всех положительных $S^{+}$ и отрицательных $S^{-}$ интеракций. \n",
    "\n",
    "Каждый пользователь описан набором заранее известных признаков (мета данных) $f_u \\subset F^U$, то же самое для объектов  $f_i \\subset F^I$.\n",
    "\n",
    "Латентное представление пользователя представлено суммой его латентных векторов признаков: \n",
    "\n",
    "$$q_u = \\sum_{j \\in f_u} e^U_j$$\n",
    "\n",
    "Аналогично для объектов: $$p_u = \\sum_{j \\in f_i} e^I_j$$\n",
    "\n",
    "Так же, по пользователю и объекту есть смещения (bias): \n",
    "\n",
    "$$b_u = \\sum_{j \\in f_u} b^U_j$$\n",
    "\n",
    "$$b_i = \\sum_{j \\in f_i} b^I_j$$\n",
    "\n",
    "Предсказание из модели будет получать через скалярное произведение эмбедингов пользователя и объекта. \n",
    "\n",
    "$$\\hat r_{ui} = f (q_u \\cdot p_i + b_u + b_i)$$\n",
    "\n",
    "Функция f() может быть разной, автор статьи выбрал сигмоиду, поскольку использовал бинарные данные.\n",
    "\n",
    "$$f(x) = \\frac{1}{1 + exp(-x)}$$\n",
    "\n",
    "Задача оптимизации будет сформулирована как максимизация правдоподобия (данных при параметрах). Обучать модель будет с помощью стохастического градиентного спуска (AdaGrad).\n",
    "\n",
    "$$L(e^U, e^I, b^U, b^I) = \\prod_{(u, i) \\in S^+} \\hat r_{ui} \\cdot  \\prod_{(u, i) \\in S^-} (1 - \\hat r_{ui})$$\n",
    "\n",
    "\n",
    "Если признаков нет, то это равноценно тому, чтобы подать на вход единичную матрицу, и просто учить эмбеддинги пользователей и объектов - сводим задачу к коллаборативной фильтрации. \n",
    "Но тогда у нас проблема холодного старта - скрытые векторы для индикаторных переменных (единиц на главной диагонали) не могут быть оценены для новых пользователей или товаров. \n",
    "\n",
    "Если наоборот, есть только фичи, а индикаторных переменных нет, то модель все равно не сводится к контентной, так как LightFM оценивает эмбеддинги признаков через факторизацию матрицы взаимодействий пользователей. В контентных моделях, в которых используется снижение размерности, факторизация происходит по матрицам совстречаемости контента (объектов)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гибридные системы\n",
    "\n",
    "Одна из классификаций:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/anamarina/RecSys_course/main/week3/images/taxonomy.png'>\n",
    "\n",
    "\n",
    "Команда Bellkor Pragmatix Chaos выиграла премию в 1 миллион долларов за решение, в котором комбинировалось 107 различных алгоритмов; их программа повысила точность рекомендательного движка Cinematch на Netflix на 10.06%. Начиная с Netflix Prize 2006-2009, более активно началось развитие гибридных рекомендательных систем. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример\n",
    "\n",
    "Кстати, к какому типу из классификации гибридных алгоритмов он относится?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/anamarina/RecSys_course/main/week3/images/twolevel.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Какие здесь могут быть плюсы/минусы при использовании подхода?\n",
    "\n",
    "\n",
    "**Плюсы:**\n",
    "- На первом уровне могут быть модели, в которые нельзявс вставить признаки, и при сборе выборке из предиктов разных моделей мы можем их добавить.\n",
    "- Все преимещуства самого бустинга, включая то, что добиваемся более высокого качества, когда учимся на ошибках предыдущих алгоритмов.\n",
    "- Довольно удобно считать feature importance и смотреть, какие модели вносят больший вклад в предсказания, а так же проанализировать значимость дополнительных признаков при ранжировании.\n",
    "- На первом уровне можно взять простые модели, которые будут довольно грубо отсекать большинство плохих кандидатов в рекомендации, но зато делать это быстро и сужая пространство хороших кандидатов. \n",
    "- Есть возможность сделать быстрый для прода пайплайн, особенно учитывая, что бейзлайны на статистиках считаются очень быстро. Например, для ALS и xgboost есть имплементации на Pyspark. \n",
    "\n",
    "**Минусы:**\n",
    "- Если на первом уровне сильная end-to-end модель и незначимые фичи на втором уровне, прироста после бустинга не будет. \n",
    "- Выборка для бустинга состоит из предсказаний после первого уровня, то есть, есть зависимость в последовательности получения данных, поэтому если обновляются кандидаты на первом уровне, часто бустинг тоже приходится обучать с нуля (т.к. предсказания с первого уровня могли сильно поменяться). \n",
    "- Появляются дополнительные параметры для тюнинга - например, число моделей на первом уровне, параметр k - длина списка рекомендаций из каждой модели первого уровня. \n",
    "- Обычно нужен дополнительный анализ предиктов с первой модели, потому что если предикты из моделей сильно скоррелированны, то будет линейная зависимость в данных. \n",
    "\n",
    "И так далее. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case study: next purchase recommendation using cascade (two-level) approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу построения рекомендательной системы для задачи рекомендации следующей покупки на соревновании [X5 retail hero](https://ods.ai/competitions/x5-retailhero-recommender-system/data). \n",
    "\n",
    "По каждому пользователю должны выдать топ-20 рекомендованных товаров и посчитать метрику качества MNAP@20.\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/anamarina/RecSys_course/main/week3/images/mnap.png' width=500 height=300>\n",
    "\n",
    "где $r_u(i)$ — бинарная оценка за тестовый период купил ли клиент товар или нет, \n",
    "\n",
    "$n_u$ — количество фактически купленных товаров пользователем за тестовый период,\n",
    "\n",
    "$U$ — множество пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: wheel in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (0.35.1)\n",
      "Requirement already satisfied: scipy in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: numpy in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from lightgbm) (1.19.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5ce5baafbc8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfunctools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregister_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcallback\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord_evaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset_parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCVBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /Users/m.ananyeva/opt/anaconda3/lib/python3.8/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = \"./\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import random\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import lightgbm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from lightfm import LightFM\n",
    "from scipy.sparse import coo_matrix, csr_matrix, save_npz\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts = pd.read_csv('purchases_sample.csv') # выборка из датасета x5\n",
    "receipts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing\n",
    "\n",
    "- Фильтрация недостаточно активных пользователей\n",
    "- Уменьшение размера множества объектов для рекомендаций (удалить непопулярные)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ditrib = receipts['item'].value_counts()[:100].rename_axis('item').reset_index(name='counts')\n",
    "fig = px.bar(ditrib, x=\"item\", y=\"counts\", color=\"counts\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_counts(df, min_item_cnt=10, min_items_per_user=0):\n",
    "    '''\n",
    "    min_item_cnt - minimum frequency of item's purchases among all receipts.\n",
    "    min_items_per_user - minimum unique items per user.\n",
    "    '''\n",
    "    item_counts = df.item.value_counts()\n",
    "    item_freq = set(item_counts[item_counts >= int(min_item_cnt)].index)\n",
    "    df = df[df.item.isin(item_freq)]\n",
    "    active_users = dict(receipts.groupby('party_rk')['item'].nunique() > min_items_per_user)\n",
    "    idxs = {k for k, v in active_users.items() if v == True}\n",
    "    df = df[df.party_rk.isin(idxs)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receipts = filter_by_counts(receipts, min_item_cnt=10, min_items_per_user=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split & cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Сплит по пользователям\n",
    "- Сплит по времени (обычный без нарушения хронологии, кросс-валидация с кумулятивным сплитом, скользящее временное окно)\n",
    "- Сплит с маскировкой n% интеракций и в train, и в test. \n",
    "\n",
    "1) 20% of all interaction pairs\n",
    "are randomly assigned to the test set, but all items and\n",
    "users are represented in the training set\n",
    "\n",
    "2) item cold-start scenario: all interactions pertaining to 20%\n",
    "of items are removed from the training set and added to\n",
    "the test set. T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Как делить данные на train и test?\n",
    "\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/anamarina/RecSys_course/main/week3/images/spliting.png' width=500 height=300>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_time(df, split_date=\"2019-02-18\", filter_train=10, filter_test=5):\n",
    "    '''\n",
    "    Function splits a data set into train and test by time.\n",
    "\n",
    "    split_date - date for split 75% train and 25% test.\n",
    "    filter_train - threshold for minimum number of unique items purchased in train period.\n",
    "    filter_test - threshold for minimum number of unique items purchased in test period.\n",
    "    '''\n",
    "    df.ymd = df.ymd.apply(lambda x: x[:10])\n",
    "    receipts_train = df[df.ymd < split_date]\n",
    "    receipts_test = df[df.ymd >= split_date]\n",
    "    \n",
    "    user_train_cnt = receipts_train[[\"party_rk\", \"item\"]].drop_duplicates().party_rk.value_counts()\n",
    "    train_users = list(user_train_cnt[user_train_cnt >= filter_train].index)\n",
    "    user_test_cnt = receipts_test[[\"party_rk\", \"item\"]].drop_duplicates().party_rk.value_counts()\n",
    "    test_users = list(user_test_cnt[user_test_cnt >= filter_test].index)\n",
    "\n",
    "    users_final = set(train_users).intersection(set(test_users))\n",
    "\n",
    "    receipts_train = receipts_train[receipts_train.party_rk.isin(users_final)]\n",
    "    receipts_test = receipts_test[receipts_test.party_rk.isin(users_final)]\n",
    "\n",
    "    assert receipts_train.party_rk.nunique() == receipts_test.party_rk.nunique()\n",
    "\n",
    "    return receipts_train, receipts_test, list(users_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date for getting 75% train and 25% test (by time)\n",
    "split_date_index = round(3 * receipts.ymd.nunique() / 4)\n",
    "split_date = sorted(receipts.ymd.unique())[split_date_index]\n",
    "\n",
    "receipts_train, receipts_test, users_final = split_by_time(receipts,\n",
    "                                                           split_date=split_date,\n",
    "                                                           filter_train=20, \n",
    "                                                           filter_test=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевод в sparse матрицы, поскольку матрицы крайне разреженные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode party_rks and items \n",
    "\n",
    "user_encoder, item_encoder = LabelEncoder(), LabelEncoder()\n",
    "user_encoder.fit(users_final)\n",
    "\n",
    "all_items = set(receipts_test.item.unique()).union(set(receipts_train.item.unique()))\n",
    "item_encoder.fit(list(all_items))\n",
    "\n",
    "receipts_train['party_rk_id'] = user_encoder.transform(receipts_train['party_rk'])\n",
    "receipts_train['item_type_id'] = item_encoder.transform(receipts_train['item'])\n",
    "\n",
    "receipts_test['party_rk_id'] = user_encoder.transform(receipts_test['party_rk'])\n",
    "receipts_test['item_type_id'] = item_encoder.transform(receipts_test['item'])\n",
    "\n",
    "matrix_shape = len(user_encoder.classes_), len(item_encoder.classes_)\n",
    "\n",
    "train_sparse = coo_matrix((list(receipts_train.item_cnt.astype(np.float32)), \n",
    "                           (list(receipts_train.party_rk_id.astype(np.int64)), \n",
    "                            list(receipts_train.item_type_id.astype(np.int64)))), shape=matrix_shape)\n",
    "\n",
    "\n",
    "test_sparse = coo_matrix((list(receipts_test.item_cnt.astype(np.float32)),\n",
    "                          (list(receipts_test.party_rk_id.astype(np.int64)), \n",
    "                           list(receipts_test.item_type_id.astype(np.int64)))), shape=matrix_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sparse.shape, test_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNAP@20 for evaluating LightFM \n",
    "\n",
    "def metric_lightfm(model, test_sparse, user_features, indices, total):\n",
    "    \n",
    "    ranks = model.predict_rank(test_sparse, num_threads=60, check_intersections=True, \\\n",
    "                               user_features=user_features)\n",
    "    mask = ranks.copy()\n",
    "    mask.data = np.less(mask.data, 20, mask.data)\n",
    "    ranks.data += 1\n",
    "    ranks.data = ranks.data * mask.data\n",
    "    ranks.eliminate_zeros()\n",
    "    ranks = ranks.tolil().data\n",
    "    average_precision_sum = 0.0\n",
    "    for x in indices:\n",
    "        n_correct_items = 0\n",
    "        precision = 0\n",
    "        for y in sorted(ranks[x]):\n",
    "            n_correct_items += 1\n",
    "            precision += n_correct_items / y\n",
    "        average_precision_sum += precision / min(total[x], 20)\n",
    "    average_precision_sum /= len(indices)\n",
    "    return average_precision_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lfm_full = LightFM(no_components=100, loss='warp', random_state=42, \n",
    "                    user_alpha=6e-5, item_alpha=2e-5, learning_rate=0.01, max_sampled=15)\n",
    "\n",
    "total = test_sparse.getnnz(axis=1)\n",
    "indices = np.nonzero(total)[0]\n",
    "\n",
    "maps = []\n",
    "epochs = 3\n",
    "for rounds in tqdm(range(7)):\n",
    "    %time model_lfm_full.fit_partial(train_sparse, sample_weight=train_sparse, epochs=epochs, \\\n",
    "                                num_threads=40, user_features=train_sparse)\n",
    "    curr_metric = metric_lightfm(model_lfm_full, test_sparse, test_sparse, indices, total)\n",
    "    maps.append(curr_metric)\n",
    "    print(curr_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BM25 Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implicit.nearest_neighbours import BM25Recommender\n",
    "from implicit.evaluation import mean_average_precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bm25 = BM25Recommender(K=150, K1=0.2, B=1.)\n",
    "model_bm25.fit(train_sparse.T.tocsr())\n",
    "print('BM25 MAP@20 ', mean_average_precision_at_k(model_bm25, train_sparse, test_sparse, K=20, num_threads=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем предсказания для второго уровня модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_data(model_bm25, train_sparse, test_sparse, top=50):\n",
    "    \n",
    "    bm25_dict, bm25_pairs = dict(), list()\n",
    "    users_test = sorted(list(set(coo_matrix(test_sparse).row)))\n",
    "    train_sparse = csr_matrix(train_sparse)\n",
    "    for i in tqdm(range(test_sparse.shape[0])):\n",
    "        rec_list, rec_set = [], set()\n",
    "        recommendations = model_bm25.recommend(i, train_sparse, N=1000, filter_already_liked_items=False)\n",
    "        for rank, recom in enumerate(recommendations):\n",
    "            if recom[1] > 0:\n",
    "                bm25_dict[(i, recom[0])] = (recom[1], rank + 1)\n",
    "                if len(rec_list) >= top:\n",
    "                    break\n",
    "                elif len(rec_list) < top:\n",
    "                    rec_list.append((i, recom[0]))\n",
    "                    rec_set.add(recom[0])\n",
    "        bm25_pairs.extend(rec_list)\n",
    "        \n",
    "    return bm25_dict, bm25_pairs\n",
    "\n",
    "\n",
    "def lightfm_data(model_lfm, users_test, items_test, top=50):\n",
    "    \n",
    "    lightfm_dict, lightfm_pairs = dict(), list()\n",
    "    user_biases, item_biases = model_lfm.user_biases[users_test], model_lfm.item_biases[items_test]\n",
    "    item_emb = model_lfm.item_embeddings[items_test]\n",
    "    user_emb = model_lfm.user_embeddings[users_test]\n",
    "    \n",
    "    preds = user_emb.dot(item_emb.T) + user_biases.reshape(-1,1) + item_biases.reshape(1,-1)\n",
    "    preds_items = (-preds).argsort(axis=1)\n",
    "    preds_scores = -np.sort(-preds, axis=1)\n",
    "    items_lfm = dict(list(zip(users_test, preds_items)))\n",
    "    lfm_scores = dict(list(zip(users_test, preds_scores)))\n",
    "    \n",
    "    user_biases_series = pd.Series(user_biases, index=users_test)\n",
    "    item_biases_series = pd.Series(item_biases, index=items_test)\n",
    "\n",
    "    for ids, user in tqdm(enumerate(users_test)):\n",
    "        current_extend = list()\n",
    "        current_scores = lfm_scores[user]\n",
    "        \n",
    "        for rank, (item, value) in enumerate(zip(items_lfm[user], current_scores)):\n",
    "            if len(current_extend) >= top:\n",
    "                break\n",
    "            elif len(current_extend) < top:\n",
    "                lightfm_dict[(user, item)] =  (value, rank + 1)\n",
    "                current_extend.append((user, item))                \n",
    "        lightfm_pairs.extend(current_extend)\n",
    "        \n",
    "    user_emb = pd.DataFrame(model_lfm.user_embeddings[users_test], index=users_test)\n",
    "    \n",
    "    return lightfm_pairs, lightfm_dict, user_biases_series, item_biases_series, user_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_dict, bm25_pairs = bm25_data(model_bm25, train_sparse, test_sparse, top=50)\n",
    "\n",
    "users_test = sorted(list(set(coo_matrix(train_sparse).row)))\n",
    "items_test = sorted(list(set(train_sparse.col)))\n",
    "\n",
    "lightfm_pairs, lightfm_dict, user_biases_series, item_biases_series, \\\n",
    "user_emb = lightfm_data(model_lfm_full, users_test, items_test, top=50)\n",
    "\n",
    "total_pairs = list(set(bm25_pairs).union(set(lightfm_pairs)))\n",
    "data_all_pairs = [pair + bm25_dict.get(pair, (np.nan, np.nan) + lightfm_dict.get(pair, (np.nan, np.nan))) for pair in tqdm(total_pairs)]\n",
    "data_all_pairs_df = pd.DataFrame(data_all_pairs, columns=[\"client_id\", \"item_id\", \"bm25_score\", \"bm25_rank\", \"lfm_score\", \"lfm_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purchases in test period for making targets\n",
    "\n",
    "purchases = list()\n",
    "\n",
    "for k in tqdm(range(test_sparse.shape[0])):\n",
    "    test_sparse = csr_matrix(test_sparse)\n",
    "    cx = scipy.sparse.coo_matrix(test_sparse[k])\n",
    "    purchased_items, client_id = [], []\n",
    "    client_id.append(k)\n",
    "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
    "        purchased_items.append(j)\n",
    "    for i in list(itertools.product(client_id, purchased_items)):\n",
    "        purchases.append(i)\n",
    "        \n",
    "def change_dtype(df):\n",
    "    df.client_id = df.client_id.astype(np.int32)\n",
    "    df.item_id = df.item_id.astype(np.int16)\n",
    "    df.bm25_score = df.bm25_score.astype(np.float32)\n",
    "    df.bm25_rank = df.bm25_rank.astype(np.float16)\n",
    "    df.lfm_score = df.lfm_score.astype(np.float32)\n",
    "    df.lfm_rank = df.lfm_rank.astype(np.float16)\n",
    "    return df\n",
    "\n",
    "def purchases2dict(purchases):\n",
    "    data_true = {}\n",
    "    for i in tqdm(purchases):\n",
    "        curr, item = i[0], int(i[1])\n",
    "        if curr not in data_true:\n",
    "            data_true[curr] = list()\n",
    "            data_true[curr].append(item)\n",
    "        else:\n",
    "            data_true[curr].append(item)\n",
    "    for i in tqdm(data_true.keys()):\n",
    "        data_true[i] = set(data_true[i])\n",
    "    return data_true\n",
    "\n",
    "data_all_pairs_df = change_dtype(data_all_pairs_df)\n",
    "data_true = purchases2dict(purchases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = data_all_pairs_df.copy()\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def average_precision(\n",
    "        dict data_true,\n",
    "        dict data_predicted,\n",
    "        const unsigned long int k\n",
    ") -> float:\n",
    "    cdef:\n",
    "        unsigned long int n_items_predicted\n",
    "        unsigned long int n_items_true\n",
    "        unsigned long int n_correct_items\n",
    "        unsigned long int item_idx\n",
    "\n",
    "        double average_precision_sum\n",
    "        double precision\n",
    "\n",
    "        set items_true\n",
    "        list items_predicted\n",
    "\n",
    "    if not data_true:\n",
    "        raise ValueError('data_true is empty')\n",
    "\n",
    "    average_precision_sum = 0.0\n",
    "\n",
    "    for key, items_true in data_true.items():\n",
    "        items_predicted = data_predicted.get(key, [])\n",
    "\n",
    "        n_items_true = len(items_true)\n",
    "        n_items_predicted = min(len(items_predicted), k)\n",
    "\n",
    "        if n_items_true == 0 or n_items_predicted == 0:\n",
    "            continue\n",
    "\n",
    "        n_correct_items = 0\n",
    "        precision = 0.0\n",
    "\n",
    "        for item_idx in range(n_items_predicted):\n",
    "            if items_predicted[item_idx] in items_true:\n",
    "                n_correct_items += 1\n",
    "                precision += <double>n_correct_items / <double>(item_idx + 1)\n",
    "\n",
    "        average_precision_sum += <double>precision / <double>min(n_items_true, k)\n",
    "\n",
    "    return average_precision_sum / <double>len(data_true)\n",
    "\n",
    "\n",
    "def metric(true_data, predicted_data, k=20):\n",
    "    true_data_set = {k: set(v) for k, v in true_data.items()}\n",
    "\n",
    "    return average_precision(true_data_set, predicted_data, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nan(data):\n",
    "    data.bm25_score.fillna(random.uniform(0, 1), inplace=True)\n",
    "    data.bm25_rank.fillna(random.randint(20, 40), inplace=True)\n",
    "    data.lfm_score.fillna(random.uniform(0, 1), inplace=True)\n",
    "    data.lfm_rank.fillna(random.randint(20, 40), inplace=True)\n",
    "    return data\n",
    "\n",
    "predictions = fill_nan(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_dict = dict(zip(receipts_train.item_type_id, receipts_train.item))\n",
    "users_dict = dict(zip(receipts_train.party_rk_id, receipts_train.party_rk))\n",
    "\n",
    "predictions['party_rk'] = predictions['client_id'].map(users_dict)\n",
    "predictions['item'] = predictions['item_id'].map(items_dict)\n",
    "\n",
    "receipts_test['target'] = 1\n",
    "\n",
    "predictions_labeled = pd.merge(predictions, receipts_test, how='left', left_on=['client_id', 'item_id'],\n",
    "                              right_on=['party_rk_id', 'item_type_id'])\n",
    "predictions_labeled.drop(columns=['party_rk_y', 'item_cnt', 'item_y', 'party_rk_id'], inplace=True)\n",
    "predictions_labeled['target'] = predictions_labeled['target'].fillna(0)\n",
    "\n",
    "data = predictions_labeled[['party_rk_x', 'item_id', 'bm25_score', 'bm25_rank', 'lfm_score', \n",
    "                                          'lfm_rank', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(), annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ids = data.party_rk_x.unique()\n",
    "index_train, index_test = train_test_split(users_ids, train_size=0.7, random_state=42)\n",
    "\n",
    "X_train = data[data.party_rk_x.isin(index_train)].reset_index(drop=True)\n",
    "X_test = data[data.party_rk_x.isin(index_test)].reset_index(drop=True)\n",
    "\n",
    "X_train[['party_rk_x', 'item_id']].drop_duplicates(inplace=True)\n",
    "X_test[['party_rk_x', 'item_id']].drop_duplicates(inplace=True)\n",
    "\n",
    "X_train.set_index(['party_rk_x', 'item_id'], inplace=True)\n",
    "X_test.set_index(['party_rk_x', 'item_id'], inplace=True)\n",
    "\n",
    "y_train, y_test = X_train.pop(\"target\"), X_test.pop(\"target\")\n",
    "\n",
    "train_data, test_data = lightgbm.Dataset(X_train, y_train), lightgbm.Dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'application': 'binary', 'objective': 'binary',\n",
    "    'metric': 'binary_logloss', \"num_threads\": 20, 'verbose': 1, 'learning_rate': 0.0001}\n",
    "\n",
    "model = lightgbm.train(params, train_data, valid_sets=test_data, num_boost_round=800,\n",
    "                       early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "# model = lightgbm.train(params, train_data, num_boost_round=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_test = data.copy()\n",
    "lgb_test[['party_rk_x', 'item_id']].drop_duplicates(inplace=True)\n",
    "lgb_test.set_index(['party_rk_x', 'item_id'], inplace=True)\n",
    "lgb_test.drop(columns='target', inplace=True)\n",
    "lgb_test[\"lgb_score\"] = model.predict(lgb_test, num_iteration=model.best_iteration)\n",
    "lgb_test = lgb_test.set_index('lgb_score', append=True).sort_values(\"lgb_score\", ascending=False)\n",
    "lgb_test.drop_duplicates(inplace=True)\n",
    "\n",
    "data_predicted = dict()\n",
    "lgb_test.reset_index(inplace=True)\n",
    "for user, group in tqdm(lgb_test.groupby(\"party_rk_x\")):\n",
    "    data_predicted[user] = list(group.item_id)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_predicted_unique = {k:list(set(v)) for (k,v) in data_predicted.items()}\n",
    "\n",
    "data_predicted_recoms = {}\n",
    "for k, v in tqdm(data_predicted_unique.items()):\n",
    "    recom = []\n",
    "    for j in v:\n",
    "        try:\n",
    "            recom.append(items_dict[j])\n",
    "        except:\n",
    "            recom.append(np.nan)\n",
    "    data_predicted_recoms[k] = recom\n",
    "\n",
    "data_predicted_df = pd.DataFrame.from_dict(data_predicted_recoms).T\n",
    "\n",
    "\n",
    "data_true = {}\n",
    "lgb_test = X_test.copy()\n",
    "lgb_test['target'] = y_test\n",
    "data_true_df = lgb_test[lgb_test['target'] != 0].reset_index()\n",
    "for user, group in tqdm(data_true_df.groupby(\"party_rk_x\")):\n",
    "    data_true[user] = list(group.item_id)\n",
    "    \n",
    "intersect = set(data_true.keys()) & set(data_predicted.keys()) # by users\n",
    "data_true_inter = {k:v for (k,v) in data_true.items() if k in intersect}\n",
    "data_predicted_inter = {k:v for (k,v) in data_predicted.items() if k in intersect}\n",
    "\n",
    "for top in [1, 5, 10, 20]:\n",
    "    print(f'mnap@{top}=', metric(data_true_inter, data_predicted_inter, k=top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://raw.githubusercontent.com/anamarina/RecSys_course/main/week3/images/validation.png' width=500 height=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
